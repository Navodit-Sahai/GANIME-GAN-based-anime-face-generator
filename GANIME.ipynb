{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrWLOZamBMmdnpOmwq1KNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navodit-Sahai/GANIME-GAN-based-anime-face-generator/blob/main/GANIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpsf44pf8Pg1"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "dataset_url=\"https://www.kaggle.com/datasets/splcher/animefacedataset\"\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "id": "_VMzWUWA8a-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "qnKHtYpd9QzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size=64\n",
        "batch_size=128\n",
        "stats=(0.5,0.5,0.5),(0.5,0.5,0.5)"
      ],
      "metadata": {
        "id": "ZjaO7gbj-d7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize(image_size),\n",
        "    T.CenterCrop(image_size),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(*stats)\n",
        "])\n",
        "\n",
        "train_ds = ImageFolder(\"/content/animefacedataset/\", transform=transform)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
      ],
      "metadata": {
        "id": "vSrxswp6-DUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating helper functions to denormalize the image tensors"
      ],
      "metadata": {
        "id": "ZOmkF1t2_yC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "KS-VKFmW-8ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denorm(image_tensors):\n",
        "  return image_tensors*stats[1][0]+stats[0][0]"
      ],
      "metadata": {
        "id": "eVKYrWXZAFxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "\n",
        "def show_batch(dl, nmax=64):\n",
        "    for images, _ in dl:\n",
        "        show_images(images, nmax)\n",
        "        break\n"
      ],
      "metadata": {
        "id": "FUFPkHy_AX21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(train_dl)"
      ],
      "metadata": {
        "id": "21t-KoEPA-Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "qsL5TFhtBBa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator=nn.Sequential(\n",
        "    nn.Conv2d(3,64,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(256,512,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(512,1,kernel_size=4,stride=1,padding=0,bias=False),\n",
        "    nn.Flatten(),\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "EOnuD8J_CMl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator"
      ],
      "metadata": {
        "id": "vT8heAhME2Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_size=128"
      ],
      "metadata": {
        "id": "FlwIdRcqDg8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator=nn.Sequential(\n",
        "    nn.ConvTranspose2d(128,512,kernel_size=4,stride=1,padding=0,bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(512,256,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(64,3,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.Tanh()\n",
        ")"
      ],
      "metadata": {
        "id": "EMWSWsKoE1ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb=torch.randn(batch_size,latent_size,1,1)#random latent tensors\n",
        "fake_images=generator(xb)\n",
        "print(fake_images.shape)\n",
        "show_images(fake_images)"
      ],
      "metadata": {
        "id": "hsJZEHLgF8QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(real_images, opt_d, device):\n",
        "  for param in discriminator.parameters():\n",
        "      param.requires_grad = True\n",
        "  for param in generator.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  opt_d.zero_grad()\n",
        "\n",
        "  # Real images\n",
        "  real_pred = discriminator(real_images)\n",
        "  real_targets = torch.ones(real_images.size(0), 1).to(device) * 0.9  # Label smoothing\n",
        "  real_loss = F.binary_cross_entropy_with_logits(real_pred, real_targets)\n",
        "  real_score = torch.sigmoid(real_pred).mean().item()  # Apply sigmoid for score\n",
        "\n",
        "  # Fake images\n",
        "  fake_latent = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "  fake_images = generator(fake_latent).detach()\n",
        "  fake_pred = discriminator(fake_images)\n",
        "  fake_targets = torch.zeros(fake_images.size(0), 1).to(device)\n",
        "  fake_loss = F.binary_cross_entropy_with_logits(fake_pred, fake_targets)  # Changed\n",
        "  fake_score = torch.sigmoid(fake_pred).mean().item()  # Apply sigmoid for score\n",
        "\n",
        "  loss = real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d.step()\n",
        "  return loss.item(), real_score, fake_score"
      ],
      "metadata": {
        "id": "UCFOlNO6GiP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator(opt_g, device):\n",
        "  for param in discriminator.parameters():\n",
        "        param.requires_grad = False\n",
        "  for param in generator.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "  opt_g.zero_grad()\n",
        "  fake_latent = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "  fake_images = generator(fake_latent)\n",
        "  target = torch.ones(batch_size, 1).to(device)\n",
        "  pred = discriminator(fake_images)\n",
        "  loss = F.binary_cross_entropy_with_logits(pred, target)\n",
        "  loss.backward()\n",
        "  opt_g.step()\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "fT7uBJgBHvMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.utils import save_image\n",
        "sample_dir='generated'\n",
        "os.makedirs(sample_dir,exist_ok=True)"
      ],
      "metadata": {
        "id": "kEAnEzWEfh-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_samples(index, latent_tensors, show=True):\n",
        "    fake_images = generator(latent_tensors)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n"
      ],
      "metadata": {
        "id": "fQtG5jeUf8C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_latent=torch.randn(64,latent_size,1,1)"
      ],
      "metadata": {
        "id": "tc7ug8qDhOvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "K3sM-13ahmyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, lr, start_index=1):\n",
        "\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    # Move fixed_latent to the device once\n",
        "    global fixed_latent\n",
        "    fixed_latent = fixed_latent.to(device)\n",
        "\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "\n",
        "            # Move data to GPU\n",
        "            real_images = real_images.to(device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d, device)\n",
        "\n",
        "            # Train Generator\n",
        "            loss_g = train_generator(opt_g, device)\n",
        "\n",
        "        # Store scalar values\n",
        "        losses_g.append(loss_g)\n",
        "        losses_d.append(loss_d)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | \"\n",
        "              f\"Loss_G: {loss_g:.4f} | \"\n",
        "              f\"Loss_D: {loss_d:.4f} | \"\n",
        "              f\"Real Score: {real_score:.4f} | \"\n",
        "              f\"Fake Score: {fake_score:.4f}\")\n",
        "\n",
        "        # Save samples once per epoch\n",
        "        save_samples(epoch + start_index, fixed_latent, show=False)\n",
        "\n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "metadata": {
        "id": "Zo18tK31iKPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0002\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "CdJR6QE8ubn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=fit(epochs,lr)"
      ],
      "metadata": {
        "id": "kET6EfFSvtM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
        "print(\"Models saved as generator.pth and discriminator.pth\")"
      ],
      "metadata": {
        "id": "IHxFkpFXHyAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lG-EDhgQciFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}